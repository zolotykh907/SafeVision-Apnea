{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm   \n",
    "import tensorflow as tf\n",
    "\n",
    "from data_processing.read_rml import get_attrubuts\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/var/data/apnea/src/vggish\")\n",
    "\n",
    "import vggish_input, vggish_params, vggish_slim\n",
    "from vggish.vggish_slim import define_vggish_slim, load_vggish_slim_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APNEA_DIR = '/var/data/apnea/mic_dataset_spec/1/'\n",
    "NO_APNEA_DIR = '/var/data/apnea/mic_dataset_spec/0/'\n",
    "\n",
    "checkpoint_path = \"/var/data/apnea/src/vggish/vggish_model.ckpt\"  \n",
    "pca_params_path = \"/var/data/apnea/src/vggish/vggish_pca_params.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Graph().as_default(), tf.compat.v1.Session() as sess:\n",
    "#     pool4_output = define_vggish_slim()\n",
    "\n",
    "#     checkpoint_path = \"/var/data/apnea/src/vggish/vggish_model.ckpt\"\n",
    "#     load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
    "\n",
    "#     for op in sess.graph.get_operations():\n",
    "#         print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(apnea_dir, no_apnea_dir):\n",
    "    apnea_files = os.listdir(apnea_dir)\n",
    "    no_apnea_files = os.listdir(no_apnea_dir)[:1500]\n",
    "    spectograms = []\n",
    "    labels = []\n",
    "\n",
    "    for apnea_file in apnea_files:\n",
    "        apnea_data = np.load(apnea_dir + apnea_file, allow_pickle=True).item()\n",
    "        \n",
    "        spectograms.append(apnea_data['spectograms'])\n",
    "        \n",
    "        labels.append(apnea_data['label'])\n",
    "\n",
    "    for no_apnea_file in no_apnea_files:\n",
    "        no_apnea_data = np.load(no_apnea_dir + no_apnea_file, allow_pickle=True).item()\n",
    "        \n",
    "        spectograms.append(no_apnea_data['spectograms'])\n",
    "        \n",
    "        labels.append(no_apnea_data['label'])\n",
    "       \n",
    "\n",
    "    return np.array(spectograms), np.array(labels)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(APNEA_DIR, NO_APNEA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма X_train: (2367, 17, 12288)\n",
      "Форма y_train: (2367,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Форма X_train:\", X_train.shape)  #(len, 17, 12288)\n",
    "print(\"Форма y_train:\", y_train.shape) #(len, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель и обучение без оптимизации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 17, 256)           3145984   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 17, 128)           32896     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,458,561\n",
      "Trainable params: 3,458,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Входной слой\n",
    "    model.add(layers.Input(shape=input_shape))  # input_shape = (17, 12288)\n",
    "\n",
    "    # Применяем Dense к каждой спектрограмме\n",
    "    model.add(layers.TimeDistributed(layers.Dense(256, activation='relu')))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(128, activation='relu')))\n",
    "\n",
    "    # BiLSTM слой для обработки временной последовательности\n",
    "    model.add(layers.Bidirectional(layers.LSTM(15, return_sequences=False)))\n",
    "\n",
    "    # Dropout для регуляризации\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Полносвязный слой\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "    # Выходной слой с одним нейроном и сигмоидной активацией\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Один выход: вероятность класса 1\n",
    "\n",
    "    return model\n",
    "\n",
    "# Пример использования\n",
    "input_shape = (17, 12288)  # Форма одного элемента датасета\n",
    "model = create_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,       \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель и обучение с оптимизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "\n",
    "space = [\n",
    "    Categorical([5, 7, 8, 10, 13, 15, 20, 25, 32, 48, 64, 100, 128, 156, 180, 256], name=\"hidden_units\"),  # Количество скрытых блоков BiLSTM\n",
    "    Categorical([0.2, 0.3, 0.4, 0.5], name=\"dropout_rate\")  # Dropout\n",
    "]\n",
    "\n",
    "def create_model(input_shape, hidden_units, dropout_rate):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Input(shape=input_shape))  # input_shape = (17, 12288)\n",
    "\n",
    "    model.add(layers.TimeDistributed(layers.Dense(256, activation='relu')))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(128, activation='relu')))\n",
    "\n",
    "    model.add(layers.Bidirectional(layers.LSTM(hidden_units, return_sequences=False)))\n",
    "\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(hidden_units, dropout_rate):\n",
    "    print(f\"Тестируем: hidden_units={hidden_units}, dropout_rate={dropout_rate}\")\n",
    "    \n",
    "    model = create_model(X_train.shape[1:], hidden_units, dropout_rate)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  \n",
    "        patience=5,       \n",
    "        restore_best_weights=True \n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
    "    print('-'*50)\n",
    "    print()\n",
    "    \n",
    "    return -f1\n",
    "\n",
    "result = gp_minimize(objective, space, n_calls=64, random_state=42)\n",
    "\n",
    "print(\"Лучшие параметры:\")\n",
    "print(f\"hidden_units: {result.x[0]}\")\n",
    "print(f\"dropout_rate: {result.x[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры:\n",
    "\n",
    "Тестируем: hidden_units=5, dropout_rate=0.5\n",
    "Precision: 0.9244604316546763, Recall: 0.8624161073825504, F1-Score: 0.892361111111111\n",
    "\n",
    "Тестируем: hidden_units=7, dropout_rate=0.4\n",
    "Precision: 0.9280575539568345, Recall: 0.8657718120805369, F1-Score: 0.8958333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Определяем пространство гиперпараметров\n",
    "search_space = [\n",
    "    Categorical([1, 3, 5, 6, 8, 10, 11, 13, 15, 17], name='hidden_units_bilstm'),  # Нейроны BiLSTM\n",
    "    Categorical([0.2, 0.3, 0.4, 0.5], name='dropout_rate')  # Dropout\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "37/37 [==============================] - 4s 63ms/step - loss: 0.6935 - accuracy: 0.5104 - precision: 0.5009 - recall: 0.4996 - val_loss: 0.6919 - val_accuracy: 0.4983 - val_precision: 1.0000 - val_recall: 0.0034\n",
      "Epoch 2/30\n",
      "37/37 [==============================] - 2s 44ms/step - loss: 0.6840 - accuracy: 0.5644 - precision: 0.5774 - recall: 0.4177 - val_loss: 0.6760 - val_accuracy: 0.5794 - val_precision: 0.7526 - val_recall: 0.2450\n",
      "Epoch 3/30\n",
      "37/37 [==============================] - 2s 44ms/step - loss: 0.5982 - accuracy: 0.6984 - precision: 0.7219 - recall: 0.6262 - val_loss: 0.5556 - val_accuracy: 0.7568 - val_precision: 0.7200 - val_recall: 0.8456\n",
      "Epoch 4/30\n",
      "37/37 [==============================] - 2s 44ms/step - loss: 0.4113 - accuracy: 0.8255 - precision: 0.8339 - recall: 0.8045 - val_loss: 0.4372 - val_accuracy: 0.8057 - val_precision: 0.8735 - val_recall: 0.7181\n",
      "Epoch 5/30\n",
      "37/37 [==============================] - 2s 44ms/step - loss: 0.2877 - accuracy: 0.9028 - precision: 0.9190 - recall: 0.8794 - val_loss: 0.4002 - val_accuracy: 0.8294 - val_precision: 0.9264 - val_recall: 0.7181\n",
      "Epoch 6/30\n",
      "37/37 [==============================] - 2s 44ms/step - loss: 0.2375 - accuracy: 0.9214 - precision: 0.9444 - recall: 0.8923 - val_loss: 0.4062 - val_accuracy: 0.8429 - val_precision: 0.9515 - val_recall: 0.7248\n",
      "Epoch 7/30\n",
      "37/37 [==============================] - 2s 47ms/step - loss: 0.2263 - accuracy: 0.9261 - precision: 0.9515 - recall: 0.8949 - val_loss: 0.3604 - val_accuracy: 0.8632 - val_precision: 0.9222 - val_recall: 0.7953\n",
      "Epoch 8/30\n",
      "37/37 [==============================] - 2s 55ms/step - loss: 0.2087 - accuracy: 0.9332 - precision: 0.9665 - recall: 0.8949 - val_loss: 0.3704 - val_accuracy: 0.8564 - val_precision: 0.9383 - val_recall: 0.7651\n",
      "Epoch 9/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1889 - accuracy: 0.9349 - precision: 0.9649 - recall: 0.9001 - val_loss: 0.3796 - val_accuracy: 0.8581 - val_precision: 0.8934 - val_recall: 0.8154\n",
      "Epoch 10/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1924 - accuracy: 0.9286 - precision: 0.9501 - recall: 0.9018 - val_loss: 0.4845 - val_accuracy: 0.7990 - val_precision: 0.9453 - val_recall: 0.6376\n",
      "Epoch 11/30\n",
      "37/37 [==============================] - 2s 63ms/step - loss: 0.1865 - accuracy: 0.9354 - precision: 0.9693 - recall: 0.8966 - val_loss: 0.3439 - val_accuracy: 0.8716 - val_precision: 0.9625 - val_recall: 0.7752\n",
      "Epoch 12/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1774 - accuracy: 0.9404 - precision: 0.9722 - recall: 0.9044 - val_loss: 0.3636 - val_accuracy: 0.8598 - val_precision: 0.9536 - val_recall: 0.7584\n",
      "Epoch 13/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1665 - accuracy: 0.9413 - precision: 0.9740 - recall: 0.9044 - val_loss: 0.3897 - val_accuracy: 0.8480 - val_precision: 0.9643 - val_recall: 0.7248\n",
      "Epoch 14/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1785 - accuracy: 0.9345 - precision: 0.9675 - recall: 0.8966 - val_loss: 0.3771 - val_accuracy: 0.8564 - val_precision: 0.9692 - val_recall: 0.7383\n",
      "Epoch 15/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1531 - accuracy: 0.9425 - precision: 0.9750 - recall: 0.9061 - val_loss: 0.4371 - val_accuracy: 0.8159 - val_precision: 0.9701 - val_recall: 0.6544\n",
      "Epoch 16/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1629 - accuracy: 0.9404 - precision: 0.9722 - recall: 0.9044 - val_loss: 0.3519 - val_accuracy: 0.8666 - val_precision: 0.9582 - val_recall: 0.7685\n",
      "Epoch 17/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1571 - accuracy: 0.9404 - precision: 0.9749 - recall: 0.9018 - val_loss: 0.3570 - val_accuracy: 0.8547 - val_precision: 0.9609 - val_recall: 0.7416\n",
      "Epoch 18/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1535 - accuracy: 0.9409 - precision: 0.9740 - recall: 0.9035 - val_loss: 0.3864 - val_accuracy: 0.8446 - val_precision: 0.9640 - val_recall: 0.7181\n",
      "Epoch 19/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1538 - accuracy: 0.9421 - precision: 0.9785 - recall: 0.9018 - val_loss: 0.3659 - val_accuracy: 0.8497 - val_precision: 0.9644 - val_recall: 0.7282\n",
      "Epoch 20/30\n",
      "37/37 [==============================] - 2s 51ms/step - loss: 0.1585 - accuracy: 0.9442 - precision: 0.9804 - recall: 0.9044 - val_loss: 0.4623 - val_accuracy: 0.8294 - val_precision: 0.9758 - val_recall: 0.6779\n",
      "Epoch 21/30\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.1516 - accuracy: 0.9399 - precision: 0.9800 - recall: 0.8960"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7fd3c4181953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;32m/var/data/apnea/.apnea/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/data/apnea/.apnea/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/data/apnea/.apnea/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/data/apnea/.apnea/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/data/apnea/.apnea/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/data/apnea/.apnea/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/var/data/apnea/.apnea/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Извлечение лучших параметров\n",
    "best_hidden_units_bilstm, best_dropout_rate = result.x\n",
    "\n",
    "# Создание и обучение модели с лучшими параметрами\n",
    "best_model = create_model(\n",
    "    input_shape=(17, 12288),\n",
    "    hidden_units=best_hidden_units_bilstm,\n",
    "    dropout_rate=best_dropout_rate\n",
    ")\n",
    "best_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    ")\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8523489932885906\n",
      "Precision: 0.8523489932885906\n",
      "Accuracy: 0.8513513513513513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "\n",
    "bin_predictions = (predictions > 0.3).astype(int)\n",
    "\n",
    "recall = recall_score(y_test, bin_predictions)\n",
    "precision = precision_score(y_test, bin_predictions)\n",
    "accuracy = accuracy_score(y_test, bin_predictions)\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".apnea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
